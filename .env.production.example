# Production Environment Variables for Vercel
# Copy this file and fill in the actual values in Vercel Dashboard

# === REQUIRED VARIABLES ===

# Database
# For Vercel Postgres: automatically provided
# For Neon/external DB: postgresql://user:password@host:5432/database?sslmode=require
DATABASE_URL=

# Authentication (REQUIRED)
# Generate with: openssl rand -base64 32
AUTH_SECRET=
# Your production URL (e.g., https://hexframe.vercel.app or https://hexframe.ai)
BETTER_AUTH_URL=

# === OPTIONAL VARIABLES ===

# External APIs (Optional - YouTube transcript features won't work without these)
# MISTRAL_API_KEY=
# YOUTUBE_API_KEY=

# === LLM PROVIDER CONFIGURATION ===

# LLM Provider Selection (optional, defaults to "openrouter")
# Options: "openrouter" or "claude-agent-sdk"
#
# - "openrouter": Multi-model proxy service with pay-per-use pricing
#   Compatible with OpenAI, Anthropic, Google, Meta, and more
#   Recommended for production due to flexibility and cost control
#
# - "claude-agent-sdk": Direct Anthropic Claude Agent SDK integration
#   Requires ANTHROPIC_API_KEY, uses async generators for streaming
#   Provides access to advanced agent capabilities and tool use
#
LLM_PROVIDER=openrouter

# OpenRouter API Key (REQUIRED if LLM_PROVIDER=openrouter)
# Get yours at: https://openrouter.ai/keys
# IMPORTANT: Set spending limits in OpenRouter dashboard for safety!
OPENROUTER_API_KEY=sk-or-v1-...

# Anthropic API Key (REQUIRED if LLM_PROVIDER=claude-agent-sdk)
# Get yours at: https://console.anthropic.com/
# Provides direct access to Claude models via the Agent SDK
ANTHROPIC_API_KEY=sk-ant-...

# Email Configuration (REQUIRED for email verification in production)
# Brevo (formerly Sendinblue) - Recommended for Hexframe
# Get your API key at: https://app.brevo.com/settings/keys/api
BREVO_API_KEY=xkeysib-...

# Email sender address (must be verified in Brevo)
EMAIL_FROM=noreply@hexframe.ai

# Alternative email providers (if not using Brevo):
# RESEND_API_KEY=re_...
# SENDGRID_API_KEY=SG...

# Inngest Configuration (REQUIRED for queue-based LLM processing)
# Sign up at: https://app.inngest.com
# Free tier: 25,000 function runs/month
INNGEST_EVENT_KEY=
INNGEST_SIGNING_KEY=

# Queue Configuration
# Set to "true" to use Inngest for long-running LLM requests
# Set to "false" to use direct calls (may timeout on Vercel)
USE_QUEUE=true

# Feature Flags (optional)
# NEXT_PUBLIC_ENABLE_OFFLINE_MODE=true
# NEXT_PUBLIC_SHOW_DEBUG_INFO=false

# Monitoring (optional)
# SENTRY_DSN=
# VERCEL_ANALYTICS_ID=